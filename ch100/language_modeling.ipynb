{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# <u>Chapter 10</u>: Chatbots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import subprocess\n",
        "import pkg_resources\n",
        "\n",
        "# Find out which packages are missing.\n",
        "installed_packages = {dist.key for dist in pkg_resources.working_set}\n",
        "required_packages = {'matplotlib', 'numpy', 'torch', 'transformers', 'torchtext', 'torchdata'}\n",
        "missing_packages = required_packages - installed_packages\n",
        "\n",
        "# If there are missing packages install them.\n",
        "if missing_packages:\n",
        "    print('Installing the following packages: ' + str(missing_packages))\n",
        "    python = sys.executable\n",
        "    subprocess.check_call([python, '-m', 'pip', 'install', *missing_packages], stdout=subprocess.DEVNULL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Building a language model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the `Transformer` model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "\n",
        "    def __init__(self, ntoken: int, d_model: int, nhead: int, d_hid: int,\n",
        "                 nlayers: int, dropout: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src: Tensor, src_mask: Tensor) -> Tensor:\n",
        "\n",
        "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "\n",
        "def generate_square_subsequent_mask(sz: int) -> Tensor:\n",
        "\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``PositionalEncoding`` module injects some information about the relative or absolute position of the tokens in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x: Tensor) -> Tensor:\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, let's Load and batch the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>']) \n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "  \n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "\n",
        "    seq_len = data.size(0) // bsz\n",
        "    print(data.size(0))\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`get_batch()` generates a pair of input-target sequences for the transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "bptt = 35\n",
        "def get_batch(source: Tensor, i: int) -> Tuple[Tensor, Tensor]:\n",
        "\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "\n",
        "    return data, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Initiate a transformer instance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a `writer` object to log various information."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Writer will output to ./runs/ directory by default\n",
        "writer = SummaryWriter()\n",
        "\n",
        "print('Current run is: ' + writer.get_logdir())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample input for the transformer.\n",
        "data, targets = get_batch(val_data, 0)\n",
        "src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "# Log the graph of the model.\n",
        "writer.add_graph(model, (data.to(device), src_mask))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the `train` and `evaluate` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0  # learning rate\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model: nn.Module) -> None:\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    \n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        \n",
        "        seq_len = data.size(0)\n",
        "        if seq_len != bptt:  # only on last batch\n",
        "            src_mask = src_mask[:seq_len, :seq_len]\n",
        "        output = model(data, src_mask)\n",
        "\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            \n",
        "            # Log the summary for the loss.\n",
        "            writer.add_scalar('Loss/train', cur_loss, (epoch-1)*num_batches+batch)\n",
        "\n",
        "            # Log the summary for the time.\n",
        "            writer.add_scalar('Time/train', ms_per_batch, (epoch-1)*num_batches+batch)\n",
        "\n",
        "            # Log the summary for the time.\n",
        "            writer.add_scalar('Perplexity/train', ppl, (epoch-1)*num_batches+batch)\n",
        "            \n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            seq_len = data.size(0)\n",
        "            if seq_len != bptt:\n",
        "                src_mask = src_mask[:seq_len, :seq_len]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += seq_len * criterion(output_flat, targets).item()\n",
        "\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can now start the training and evaluation processes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 20\n",
        "best_model = None\n",
        "\n",
        "# Iterate over all epochs.\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model)\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    val_ppl = math.exp(val_loss)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "    print('-' * 89)\n",
        "    \n",
        "    # Log the summary for the loss.\n",
        "    writer.add_scalar('Loss/eval', val_loss, epoch)\n",
        "\n",
        "    # Log the summary for the time.\n",
        "    writer.add_scalar('Time/eval', elapsed, epoch)\n",
        "\n",
        "    # Log the summary for the time.\n",
        "    writer.add_scalar('Perplexity/eval', val_ppl, epoch)\n",
        "    \n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "writer.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally, we can evaluate the best model on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_loss = evaluate(best_model, test_data)\n",
        "test_ppl = math.exp(test_loss)\n",
        "print('=' * 89)\n",
        "print(f'| End of training | test loss {test_loss:5.2f} | '\n",
        "      f'test ppl {test_ppl:8.2f}')\n",
        "print('=' * 89)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tensoboard is an open-source tool to track the output of machine learning experiments and visualize different quantities during the workflow. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir runs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Executing the following command initiates the process of gathering all the relevant files from the local repository and uploading them to the service."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!tensorboard dev upload \\\n",
        "  --logdir runs \\\n",
        "  --name \"My ML4Text experiment\" \\\n",
        "  --description \"Comparing two language models\" \\\n",
        "  --one_shot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XKCD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`XKCD` (https://xkcd.com/) is a famous webcomic based on statements on life and love, mathematical, programming, and scientific inside jokes. \n",
        "\n",
        "We present the validation loss for each epoch and annotation that points to the best mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Sample validation loss for 20 epochs.\n",
        "val_loss_array = [5.79, 5.63, 5.599, 5.603, 5.502, 5.503, 5.52, 5.523, 5.52, 5.477, 5.49, 5.513, 5.511, 5.533, 5.518, 5.549, 5.509, 5.533, 5.539, 5.542]\n",
        "\n",
        "# Create an xkcd plot that shows which epoch produced the best model.\n",
        "with plt.xkcd():\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_axes((0.1, 0.2, 0.8, 0.7))\n",
        "    ax.set_yticks([5.5, 5.6, 5.7, 5.8])\n",
        "    plt.xticks(np.arange(20), np.arange(1, 21))\n",
        "    ax.set_ylim([5.4, 5.9])\n",
        "\n",
        "    # Include an annotation pointing to the best model.\n",
        "    ax.annotate(\n",
        "        'HERE YOU WILL FIND\\nTHE BEST MODEL!',\n",
        "        xy=(9, 5.5), arrowprops=dict(arrowstyle='->'), xytext=(5, 5.7))\n",
        "\n",
        "    ax.plot(val_loss_array)\n",
        "\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Validation loss')\n",
        "    fig.text(0.5, 0.05, '', ha='center')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following method creates a stick figure, with a callout."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the stick figure.\n",
        "def stick_figure(ax, x=.5, y=.5, radius=.03, callout=None, color='k', lw=2, xytext=(0, 20)):\n",
        "    \n",
        "    # Draw the head.\n",
        "    head = plt.Circle((x, y), radius=radius, transform=ax.transAxes, \n",
        "                      edgecolor=color, lw=lw, facecolor='none', zorder=10)\n",
        "    ax.add_patch(head)\n",
        "    \n",
        "    # Draw the body.\n",
        "    body = plt.Line2D([x, x], [y-radius, y-(radius * 4)], \n",
        "                      color=color, lw=lw, transform=ax.transAxes)\n",
        "    ax.add_line(body)\n",
        "    \n",
        "    # Draw the arms.\n",
        "    left_arm = plt.Line2D([x, x-(radius * .8)], [y-(radius * 1.5), y-(radius*5)], \n",
        "                    color=color, lw=lw, transform=ax.transAxes)\n",
        "    ax.add_line(left_arm)\n",
        "    right_arm = plt.Line2D([x, x+(radius)], [y-(radius * 1.5), y-(radius*5)], \n",
        "                      color=color, lw=lw, transform=ax.transAxes)\n",
        "    ax.add_line(right_arm)\n",
        "\n",
        "    # Draw the legs.\n",
        "    left_leg = plt.Line2D([x, x-(radius*.5)], [y-(radius * 4), y-(radius*8)], \n",
        "                      color=color, lw=lw, transform=ax.transAxes)\n",
        "    ax.add_line(left_leg)\n",
        "    right_leg = plt.Line2D([x, x+(radius)], [y-(radius * 4), y-(radius*8)], \n",
        "                    color=color, lw=lw, transform=ax.transAxes)\n",
        "    ax.add_line(right_leg)\n",
        "    \n",
        "    # Show the message of the figure.\n",
        "    if callout:\n",
        "        ax.annotate(callout, xy=(x+radius, y+radius), xytext=xytext,\n",
        "                    xycoords='axes fraction', textcoords='offset points',\n",
        "                    arrowprops=dict(arrowstyle='-', lw=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also print the architecture of the model created earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# Create an xkcd plot that shows the model's architecture.\n",
        "with plt.xkcd():\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(12, 11))\n",
        "    ax.axis('off')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Include an annotation with the model's architecture.\n",
        "    ax.annotate(best_model, xy=(0.2, 0.))\n",
        "   \n",
        "    # Draw the figure.\n",
        "    stick_figure(ax, x=.03, y=.6, radius=.02, callout='What a model!')\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Machine Learning Techniques for Text \n",
        "&copy;2021&ndash;2022, Nikos Tsourakis, <nikos@tsourakis.net>, Packt Publications. All Rights Reserved."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "8f1e200aa4e9598f1b1017d8bb6526388dc3fae44f5def43455ba665e800f8e8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
