{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Chapter 9</u>: Generating Text in Chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "# Find out which packages are missing.\n",
    "installed_packages = {dist.key for dist in pkg_resources.working_set}\n",
    "required_packages = {'torch', 'transformers', 'gradio'}\n",
    "missing_packages = required_packages - installed_packages\n",
    "\n",
    "# If there are missing packages install them.\n",
    "if missing_packages:\n",
    "    print('Installing the following packages: ' + str(missing_packages))\n",
    "    python = sys.executable\n",
    "    subprocess.check_call([python, '-m', 'pip', 'install', *missing_packages], stdout=subprocess.DEVNULL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a generative chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a generative chatbot and to make the interaction more enjoyable, we use the pre-trained model _microsoft/DialoGPT-medium_ that is specifically designed for this task. \n",
    "\n",
    "The _chat_ method that follows is responsible for receiving the user input and generating a response from the bot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    " \n",
    "# Load the models.\n",
    "model_name = \"microsoft/DialoGPT-medium\"\n",
    " \n",
    "gpt2_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "gpt2_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Chat with the bot using a new input and the previous history.\n",
    "def chat(input, history=[], gen_kwargs=[]):\n",
    "    \n",
    "    # Tokenize the input.\n",
    "    input_ids = gpt2_tokenizer.encode(input+gpt2_tokenizer.eos_token, return_tensors='pt')\n",
    "\n",
    "    # Update the dialogue history.\n",
    "    bot_input_ids = torch.cat([torch.LongTensor(history), input_ids], dim=-1)\n",
    "\n",
    "    # Generate the response of the bot. \n",
    "    new_history = gpt2_model.generate(bot_input_ids, **gen_kwargs).tolist()\n",
    "\n",
    "    # Convert the tokens to text.\n",
    "    output = gpt2_tokenizer.decode(new_history[0]).split(\"<|endoftext|>\")\n",
    "    output = [(output[i], output[i+1]) for i in range(0, len(output)-1, 2)]\n",
    "\n",
    "    return output, new_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simulate a multi-turn dialog generation requesting advice from the chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me:\t What is your best advice?\n",
      "Bot:\t Don't be a loser.\n",
      "---------------\n",
      "Me:\t Does money buy happiness?\n",
      "Bot:\t It does if you're a loser.\n",
      "---------------\n",
      "Me:\t Do you have money?\n",
      "Bot:\t I have a lot of money.\n",
      "---------------\n",
      "Me:\t Did you buy happiness?\n",
      "Bot:\t I bought happiness.\n",
      "---------------\n",
      "Me:\t Well done...\n",
      "Bot:\t I'm a happy guy.\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model.\n",
    "gen_kwargs = {\n",
    "    \"max_length\":1000,\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": False,\n",
    "    \"pad_token_id\": gpt2_tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "# Simulate the chat.\n",
    "me = [\"What is your best advice?\", \"Does money buy happiness?\", \"Do you have money?\", \"Did you buy happiness?\", \"Well done...\"]\n",
    "history = []\n",
    "\n",
    "for user_input in me:\n",
    "    output, history = chat(user_input, history, gen_kwargs)\n",
    "    print(\"Me:\\t\", user_input) \n",
    "    print(\"Bot:\\t\", output[len(output)-1][1])\n",
    "    print(\"---------------\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the _do_sample_ parameter is set to _False_ greedy decoding is used. Otherwise sampling is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Me:\t What is your best advice?\n",
      "Bot:\t Live life confidence man.\n",
      "---------------\n",
      "Me:\t Does money buy happiness?\n",
      "Bot:\t Checks OP name Nope.\n",
      "---------------\n",
      "Me:\t Do you have money?\n",
      "Bot:\t Checks OP name Yep.\n",
      "---------------\n",
      "Me:\t Did you buy happiness?\n",
      "Bot:\t Yes. Have you built happiness?\n",
      "---------------\n",
      "Me:\t Well done...\n",
      "Bot:\t Are you good at discerning monarchry from russian tongue?\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "# Parameters for the model.\n",
    "gen_kwargs = {\n",
    "    \"max_length\":1000,\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": gpt2_tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "# Simulate the chat.\n",
    "history = []\n",
    "\n",
    "for user_input in me:\n",
    "    output, history = chat(user_input, history, gen_kwargs)\n",
    "    print(\"Me:\\t\", user_input) \n",
    "    print(\"Bot:\\t\", output[len(output)-1][1])\n",
    "    print(\"---------------\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the GUI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code snippet, we create the visual components of the interface and show the GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import datetime as dt\n",
    "from tkinter import *\n",
    "\n",
    "# Parameters for the model.\n",
    "gen_kwargs = {\n",
    "    \"max_length\":1000,\n",
    "    \"min_length\":-1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": False,\n",
    "    \"pad_token_id\": gpt2_tokenizer.eos_token_id\n",
    "}\n",
    "\n",
    "# A GUI for the chat application.\n",
    "class Chatty:\n",
    "\n",
    "    # Keep track of the dialogue history.\n",
    "    history = []\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.window = Tk()\n",
    "        self.setup_gui()\n",
    "        \n",
    "    def run(self):\n",
    "        self.window.mainloop()\n",
    "    \n",
    "    # Method to create the different GUI elements.\n",
    "    def setup_gui(self):\n",
    "        self.window.title(\"chatty\")\n",
    "        self.window.resizable(width=False, height=False)\n",
    "        self.window.configure(width=550, height=500, bg=\"#17202A\")\n",
    "        \n",
    "        # Add the head label.\n",
    "        self.profile_img = PhotoImage(file='./images/user-online.png')\n",
    "        head_label = Label(self.window, bg=\"#17202A\", fg=\"#EAECEE\", compound=LEFT,\n",
    "                           text=\"Nick Brioche\", font=\"Helvetica 13 bold\", pady=0, image=self.profile_img)\n",
    "        head_label.place(relwidth=1)\n",
    "        \n",
    "        # Add a line divider.\n",
    "        div_line = Label(self.window, width=450, bg=\"#ABB2B9\")\n",
    "        div_line.place(relwidth=1, rely=0.07, relheight=0.012)\n",
    "        \n",
    "        # Add the text area.\n",
    "        self.text_area = Text(self.window, width=20, height=2, bg=\"white\", fg=\"#EAECEE\",\n",
    "                                font=\"Helvetica 14\", padx=15, pady=5)\n",
    "        self.text_area.place(relheight=0.745, relwidth=1, rely=0.08)\n",
    "        self.text_area.configure(cursor=\"arrow\", state=DISABLED)\n",
    "        \n",
    "        # Add a scroll bar.\n",
    "        scroll_bar = Scrollbar(self.text_area)\n",
    "        scroll_bar.place(relheight=1, relx=1.0)\n",
    "        scroll_bar.configure(command=self.text_area.yview)\n",
    "        \n",
    "        # Add a bottom label.\n",
    "        bottom_label = Label(self.window, bg=\"#ABB2B9\", height=80)\n",
    "        bottom_label.place(relwidth=1, rely=0.825)\n",
    "        \n",
    "        # Add an input entry box.\n",
    "        self.input_entry = Entry(bottom_label, bg=\"#6a747e\", fg=\"#EAECEE\", font=\"Helvetica 14\")\n",
    "        self.input_entry.place(relwidth=0.74, relheight=0.07, rely=0.0, relx=0.0)\n",
    "        self.input_entry.focus()\n",
    "        self.input_entry.bind(\"<Return>\", self.on_enter_pressed)\n",
    "        \n",
    "        # Create the send button.\n",
    "        send_button = Button(bottom_label, text=\"Send\", bd=0, bg=\"#ABB2B9\", \n",
    "                             command=lambda: self.on_enter_pressed(None))\n",
    "        self.send_img = PhotoImage(file='./images/send.png')\n",
    "        send_button.config(image=self.send_img)\n",
    "        send_button.place(relx=0.77, rely=0.0, relheight=0.07, relwidth=0.22)\n",
    "    \n",
    "    # Method to capture the press of the Enter button.\n",
    "    def on_enter_pressed(self, event):\n",
    "        msg = self.input_entry.get()\n",
    "        self.chatbot(msg)\n",
    "\n",
    "    # Chat with the bot.\n",
    "    def chatbot(self, msg):\n",
    "\n",
    "        # Skip empty input.\n",
    "        if not msg: return\n",
    "        \n",
    "        # Show the request on the GUI.\n",
    "        self.input_entry.delete(0, END)\n",
    "        request = f\"{msg}\\n\\n\"\n",
    "        self.text_area.configure(state=NORMAL)\n",
    "        self.text_area.tag_config('request', foreground=\"black\", wrap='word')\n",
    "        self.text_area.insert(END, request, 'request')\n",
    "        self.text_area.configure(state=DISABLED)\n",
    "        \n",
    "        # Get the bot's response.\n",
    "        output, self.history = chat(msg, self.history, gen_kwargs)\n",
    "        response = f\"{output[len(output)-1][1]}\\n\\n\"\n",
    "       \n",
    "        # Show the response on the GUI.\n",
    "        self.text_area.configure(state=NORMAL)\n",
    "        self.text_area.tag_config('response', justify='right', foreground=\"black\", \n",
    "                                    background=\"lightgreen\", wrap='word', rmargin=10)\n",
    "        self.text_area.insert(END, response, 'response')\n",
    "        self.text_area.configure(state=DISABLED)\n",
    "        \n",
    "        self.text_area.see(END)\n",
    "        \n",
    "# Run the chat application.\n",
    "if __name__ == \"__main__\":\n",
    "    app = Chatty()\n",
    "    # Uncomment to show the GUI when running the notebook in your local PC.\n",
    "    #app.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Gradio` (https://gradio.app/) can be used to create the web version of the GUI, so we need to adapt the Python code to include HTML tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat with the bot using a new input and the previous history.\n",
    "# Return a basic HTML including the dialogue.\n",
    "def chat_html(input, history=[]):\n",
    "\n",
    "    # Skip empty input.\n",
    "    if not input: return\n",
    "\n",
    "    output, history = chat(input, history, gen_kwargs)\n",
    "    \n",
    "    # Create the HTML.\n",
    "    html = \"<div class='chatbot'>\"\n",
    "    for tuple in output:\n",
    "        for m, msg in enumerate(tuple):\n",
    "            cls = \"user\" if m%2 == 0 else \"bot\"\n",
    "            html += \"<div class='msg {}'> {}</div>\".format(cls, msg)\n",
    "        html += \"</div>\"\n",
    "    \n",
    "    return html, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the specifics of the gradio module, we can run the chat application on a local web server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsouraki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\inputs.py:26: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  warnings.warn(\n",
      "c:\\Users\\tsouraki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Users\\tsouraki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: `numeric` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n",
      "c:\\Users\\tsouraki\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.3, however version 3.14.0 is available, please upgrade.\n",
      "--------\n",
      "Running on local URL:  http://127.0.0.1:7862\n",
      "Running on public URL: https://cc06b0e067d86def.gradio.app\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://www.huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://cc06b0e067d86def.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x1d1ebb77460>,\n",
       " 'http://127.0.0.1:7862/',\n",
       " 'https://cc06b0e067d86def.gradio.app')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Setup the style of the GUI.\n",
    "css = \"\"\"\n",
    ".chatbox {display:flex;flex-direction:column}\n",
    ".msg {padding:4px;margin-bottom:4px;border-radius:4px;width:80%}\n",
    ".msg.user {background-color:cornflowerblue;color:white}\n",
    ".msg.bot {background-color:lightgray;align-self:self-end}\n",
    ".footer {display:none !important}\n",
    "\"\"\"\n",
    "\n",
    "# Launch the interface.\n",
    "gr.Interface(fn=chat_html, theme=\"default\",\n",
    "             inputs=[gr.inputs.Textbox(placeholder=\"Hello!\"), \"state\"],\n",
    "             outputs=[\"html\", \"state\"], css=css).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we have learned â€¦\n",
    "\n",
    "| |\n",
    "| --- |\n",
    "| **Tools**<ul><li>GUI Programming</li></ul> |\n",
    "| |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "34c3ec88db1a123a786d67d086f3ede88281b71e687e4350202a680e0c5fcbcd"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "8f1e200aa4e9598f1b1017d8bb6526388dc3fae44f5def43455ba665e800f8e8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
